{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "清楚了解 L1, L2 的意義與差異為何，並了解 LASSO 與 Ridge 之間的差異與使用情境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請閱讀相關文獻，並回答下列問題\n",
    "\n",
    "[脊回歸 (Ridge Regression)](https://blog.csdn.net/daunxx/article/details/51578787)\n",
    "[Linear, Ridge, Lasso Regression 本質區別](https://www.zhihu.com/question/38121173)\n",
    "\n",
    "1. LASSO 回歸可以被用來作為 Feature selection 的工具，請了解 LASSO 模型為什麼可用來作 Feature selection\n",
    "2. 當自變數 (X) 存在高度共線性時，Ridge Regression 可以處理這樣的問題嗎?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1.使用LASSO時，當alpha逐漸加大，較為不重要的特徵會被縮減為0，故可以透過適當放大alpha值來篩掉部份特徵；相對Ridge不會將特徵的權重降為0，所以不存在Feature selection的效果。\n",
    "2.Ridge Regression可以有效限制各個自變數的權重，故可以處理當自變數存在共線性時，權重系統會過度膨脹的問題。\n",
    "\n",
    "==============\n",
    "http://dasanlin888.pixnet.net/blog/post/442485077-%E5%88%A9%E7%94%A8ncss%E7%9A%84%E8%84%8A%E8%BF%B4%E6%AD%B8%EF%BC%88ridge-regression%EF%BC%89%E8%A7%A3%E9%87%8B%E5%A4%9A%E5%85%83%E5%85%B1\n",
    "\n",
    "https://taweihuang.hpd.io/2016/09/12/%E8%AE%80%E8%80%85%E6%8F%90%E5%95%8F%EF%BC%9A%E5%A4%9A%E5%85%83%E8%BF%B4%E6%AD%B8%E5%88%86%E6%9E%90%E7%9A%84%E8%AE%8A%E6%95%B8%E9%81%B8%E6%93%87/\n",
    "\n",
    "https://taweihuang.hpd.io/2018/06/10/pca-%E8%88%87-ridge-regression-%E7%9A%84%E9%97%9C%E4%BF%82/\n",
    "\n",
    "http://personal.psu.edu/jol2/course/stat597e/notes2/lreg.pdf\n",
    "\n",
    "http://statweb.stanford.edu/~tibs/sta305files/Rudyregularization.pdf\n",
    "\n",
    "1.LASSO的正規化可以強制使得不重要的解釋變數Xj其估計出的特徵係數Bj=0，因此也達到了變數選擇的功能。\n",
    "2.可以，Ridge Regeression主要功能並非篩選特徵，而是消除變數間的共線性問題，做法上類似PCA的特徵融合；與一般最小平方法估計最大的差異，是希望能夠控制每個變數的係數大小，因此其目標函數會多加入係數大小的二次懲罰項，其中 lambda 越大，代表我們希望迴歸係數越靠近 0。跟暴力設 PC 係數為 0 的結果比較，差別在 ridge regression 將係數轉換成平滑的函數做收縮，針對這些投影量用收縮因子進行收縮，得到了收縮後的向量。而且，對於第二個 PC 的收縮強度比第一個 PC 的收縮強度強。\n",
    "\n",
    "==============\n",
    "\n",
    "1.https://zh.wikipedia.org/wiki/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9 該方法給回歸係數加入了L1懲罰，導致其中的許多參數趨於零。任何回歸係數不為零的特徵都會被LASSO算法「選中」。\n",
    "2.https://blog.csdn.net/daunxx/article/details/51578787 当使用最小二乘法计算线性回归模型参数的时候，如果数据集合矩阵（也叫做设计矩阵(design matrix)）X，存在多重共线性，那么最小二乘法对输入变量中的噪声非常的敏感，其解会极为不稳定。为了解决这个问题，就有了这一节脊回归（Ridge Regression ）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
